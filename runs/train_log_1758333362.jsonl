{"episode": 1, "reward": -1.28, "score": 0, "steps": 29, "epsilon": 1.0, "avg_loss": null}
{"episode": 2, "reward": -1.26, "score": 0, "steps": 27, "epsilon": 1.0, "avg_loss": null}
{"episode": 3, "reward": -1.28, "score": 0, "steps": 29, "epsilon": 1.0, "avg_loss": null}
{"episode": 4, "reward": -1.07, "score": 0, "steps": 8, "epsilon": 1.0, "avg_loss": null}
{"episode": 5, "reward": -1.13, "score": 0, "steps": 14, "epsilon": 1.0, "avg_loss": null}
{"episode": 6, "reward": -1.21, "score": 0, "steps": 22, "epsilon": 1.0, "avg_loss": null}
{"episode": 7, "reward": -1.29, "score": 0, "steps": 30, "epsilon": 1.0, "avg_loss": null}
{"episode": 8, "reward": -0.5200000000000002, "score": 1, "steps": 54, "epsilon": 1.0, "avg_loss": null}
{"episode": 9, "reward": -1.29, "score": 0, "steps": 30, "epsilon": 1.0, "avg_loss": null}
{"episode": 10, "reward": -1.29, "score": 0, "steps": 30, "epsilon": 1.0, "avg_loss": null}
{"episode": 11, "reward": -0.3700000000000001, "score": 1, "steps": 39, "epsilon": 1.0, "avg_loss": null}
{"episode": 12, "reward": -1.09, "score": 0, "steps": 10, "epsilon": 1.0, "avg_loss": null}
{"episode": 13, "reward": -1.18, "score": 0, "steps": 19, "epsilon": 1.0, "avg_loss": null}
{"episode": 14, "reward": -1.15, "score": 0, "steps": 16, "epsilon": 1.0, "avg_loss": null}
{"episode": 15, "reward": -1.1, "score": 0, "steps": 11, "epsilon": 1.0, "avg_loss": null}
{"episode": 16, "reward": -1.36, "score": 0, "steps": 37, "epsilon": 1.0, "avg_loss": null}
{"episode": 17, "reward": -1.26, "score": 0, "steps": 27, "epsilon": 1.0, "avg_loss": null}
{"episode": 18, "reward": -1.18, "score": 0, "steps": 19, "epsilon": 1.0, "avg_loss": null}
{"episode": 19, "reward": -1.17, "score": 0, "steps": 18, "epsilon": 1.0, "avg_loss": null}
{"episode": 20, "reward": -1.2, "score": 0, "steps": 21, "epsilon": 1.0, "avg_loss": null}
{"episode": 21, "reward": -1.14, "score": 0, "steps": 15, "epsilon": 1.0, "avg_loss": null}
{"episode": 22, "reward": -0.2400000000000001, "score": 1, "steps": 26, "epsilon": 1.0, "avg_loss": null}
{"episode": 23, "reward": -1.22, "score": 0, "steps": 23, "epsilon": 1.0, "avg_loss": null}
{"episode": 24, "reward": -1.13, "score": 0, "steps": 14, "epsilon": 1.0, "avg_loss": null}
{"episode": 25, "reward": -1.37, "score": 0, "steps": 38, "epsilon": 1.0, "avg_loss": null}
{"episode": 26, "reward": -1.18, "score": 0, "steps": 19, "epsilon": 1.0, "avg_loss": null}
{"episode": 27, "reward": -1.37, "score": 0, "steps": 38, "epsilon": 1.0, "avg_loss": null}
